import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from pathlib import Path
from tensorflow.keras.preprocessing import image_dataset_from_directory


import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from skimage.color import rgb2gray
from skimage.transform import resize

folder_names = [
    "Anthracnose",
    "Bacterial Canker",
    "Cutting Weevil",
    "Die Back",
    "Gall Midge",
    "Healthy",
    "Powdery Mildew",
    "Sooty Mould",
]

def filter_subdirs(subdirs):
    return [subdir for subdir in subdirs if Path(subdir).name in folder_names]

# Set dataset path and create ImageDataGenerator for data augmentation
data_dir = Path('/content')
train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   validation_split=0.2)

train_generator = train_datagen.flow_from_directory(data_dir,
                                                    target_size=(260, 260),
                                                    batch_size=32,
                                                    class_mode='categorical',
                                                    subset='training',
                                                    classes=folder_names)
validation_generator = train_datagen.flow_from_directory(data_dir,
                                                         target_size=(260, 260),
                                                         batch_size=32,
                                                         class_mode='categorical',
                                                         subset='validation',
                                                         classes=folder_names)

"""# EDA"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

"""**Create a function to count the number of images per class:**"""

def count_images_per_class(folder_names, data_dir):
    class_counts = {}
    for folder in folder_names:
        class_path = data_dir / folder
        num_images = len(list(class_path.glob('*.jpg')))  # assuming the images are in jpg format
        class_counts[folder] = num_images
    return class_counts

class_counts = count_images_per_class(folder_names, data_dir)
class_counts_df = pd.DataFrame.from_dict(class_counts, orient='index', columns=['count'])

plt.figure(figsize=(12, 6))
sns.barplot(data=class_counts_df.reset_index(), x='index', y='count')
plt.xlabel('Class')
plt.ylabel('Number of Images')
plt.title('Distribution of Images Across Classes')
plt.xticks(rotation=45)
plt.show()

from PIL import Image
import random

"""**Create a function to display sample images from each class:**"""

def display_sample_images(folder_names, data_dir, num_samples=3):
    fig, axes = plt.subplots(len(folder_names), num_samples, figsize=(12, 2 * len(folder_names)))
    
    for i, folder in enumerate(folder_names):
        class_path = data_dir / folder
        image_files = list(class_path.glob('*.jpg'))
        samples = random.sample(image_files, num_samples)
        
        for j, image_file in enumerate(samples):
            img = Image.open(image_file)
            axes[i, j].imshow(img)
            axes[i, j].set_axis_off()
            
            if j == 0:
                axes[i, j].set_title(folder)
    
    plt.subplots_adjust(wspace=0.05, hspace=0.25)
    plt.show()

display_sample_images(folder_names, data_dir)

"""**Create a function to compute the average image dimensions:**"""

def compute_average_dimensions(folder_names, data_dir):
    total_images = 0
    total_width = 0
    total_height = 0
    
    for folder in folder_names:
        class_path = data_dir / folder
        image_files = list(class_path.glob('*.jpg'))
        
        for image_file in image_files:
            img = Image.open(image_file)
            total_width += img.width
            total_height += img.height
            total_images += 1
    
    avg_width = total_width / total_images
    avg_height = total_height / total_images
    
    return avg_width, avg_height

"""**Compute the average image dimensions:**"""

avg_width, avg_height = compute_average_dimensions(folder_names, data_dir)
print(f"Average width: {avg_width:.2f}, Average height: {avg_height:.2f}")

"""# Model Building

**!. CNN**
"""

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(260, 260, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(8, activation='softmax')  # Number of classes (8) for the mango leaf diseases
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    epochs=100,
                    validation_data=validation_generator,
                    validation_steps=len(validation_generator))

plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.save('/content/drive/MyDrive/Mango Leaf Desiease Detect/Best_Model.h5')

# model=tf.keras.models.load_model('/content/drive/MyDrive/Mango Leaf Desiease Detect/Best_Model.h5')

model.evaluate(validation_generator)

# Extract images and labels from the train_generator
images = []
labels = []
for i in range(len(train_generator)):
    batch_images, batch_labels = train_generator[i]
    images.extend(batch_images)
    labels.extend(np.argmax(batch_labels, axis=1))
    
# Convert images and labels to numpy arrays
images = np.array(images)
labels = np.array(labels)

# Flatten and convert to grayscale
X = [resize(rgb2gray(img), (260, 260)).flatten() for img in images]
y = labels

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Other Machine Learning Models"""

# Define the models
models = {
    'SVM': SVC(),
    'KNN': KNeighborsClassifier(),
    'Random Forest': RandomForestClassifier()
}

# Train and evaluate the models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    print(f"{name}:")
    print(f"  Accuracy: {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")
    print(f"  F1-score: {f1:.4f}")
    print()

